# GitHub Copilot Instructions

## Commit Message Format

Always use Arlo's Risk-Aware Commit Notation for all commit messages in this project.

### Format: `[Risk Level][Intention] Description of what the code now does`

#### Risk Levels:
- **`.`** (Safe/Proven) - Addresses all known and unknown risks. Provable refactorings, developer-only changes.
- **`^`** (Validated) - Addresses all known risks. Test-supported changes, verified behavior.
- **`!`** (Risky) - Some known risks remain unverified. Unit tests for new behavior, but manual execution.
- **`@`** (Probably Broken) - No risk attestation. No tests, unfinished, or unverified.

#### Core Intentions:
- **`F/f`** - Feature (changes 1 behavior)
- **`B/b`** - Bugfix (repairs 1 undesirable behavior)
- **`R/r`** - Refactoring (0 behavior changes, 1 structure change)
- **`D/d`** - Documentation (0 behavior changes)
- **`T/t`** - Testing (0 behavior changes, 1 test change)

#### Important Rules:
1. Features/bugfixes > 8 lines of code automatically become risky (`!`) or broken (`@`)
2. Use present tense, describe what the code now does, not what you changed
3. Case meaning (decide as team): UPPERCASE = intended behavior change OR user-visible change
4. Always include risk level and intention - no exceptions

#### Examples:
- `". r Extracts API functions from main controller"` - Safe refactoring via tool
- `"^ F Compiles Doculisp files to markdown output"` - Validated feature with tests
- `"! B Handles malformed Doculisp syntax gracefully"` - Risky bugfix, manual verification
- `"@ F Supports nested include blocks"` - Unfinished/unverified feature

#### Reference:
https://github.com/RefactoringCombos/ArlosCommitNotation

## Documentation Guidelines

When writing or updating documentation, always reference the **AI Assistant Codex** (`AI-Assistant-Codex.md`) for:

- **Doculisp DSL Syntax**: Proper structure, blocks, and formatting patterns
- **File Organization**: Naming conventions, directory structure, and modular organization
- **Best Practices**: Content strategy, development workflow, and error prevention
- **Common Workflows**: Standard patterns for different document types and structures
- **Syntax Rules**: Critical file type rules, parameter limits, and escape sequences

### Key Documentation Requirements:
- Use `.dlisp` files for structure-only documents (no text content)
- Use `.md` files with embedded Doculisp blocks for documents with text content
- Always use dynamic headings `<!-- (dl (# Title)) -->` in .md files intended for Doculisp compilation
- Wrap all Doculisp code in HTML comments when in .md files: `<!-- (dl ...) -->`
- Follow modular organization principles with clear file naming conventions
- Use approval testing patterns when documenting complex structures

## Parser Internals Understanding Guidelines

When working with the core parsing infrastructure, creating new parsers, or modifying parser behavior, always reference the **AI Parser Internals Codex** (`AI-Parser-Internals-Codex.md`) for:

- **Parser Architecture**: Generic parser system design and composable handler architecture
- **Data Structure Types**: All parsing result types (`StepParseResult`, `ISubParseResult`, `IDiscardResult`, etc.)
- **Handler Patterns**: Standard patterns for creating parser handler functions
- **Chain Logic**: How the `mapFirst` function coordinates handler execution
- **Location Tracking**: Precise location maintenance throughout parsing operations
- **Error Propagation**: How errors flow through the parsing chain with context
- **Performance Patterns**: Optimization strategies and trade-offs in parser design

### Key Parser Internals Integration Requirements:
- Use the three handler return patterns: parse result, discard, or no result found
- Implement proper location tracking with `current.increaseChar()` and `current.increaseLine()`
- Follow the handler signature: `(input: TParse, current: ILocation) => StepParseResult<TParse, TResult>`
- Use `internals.createStringParser()` or `internals.createArrayParser()` for parser creation
- Apply `internals.noResultFound()` when handler doesn't match
- Use `internals.stopFindingResults()` for early termination
- Implement immutable parsing operations that don't modify input
- Build composable handlers that can be reused across different parsers

## Document Parser Understanding Guidelines

When working with document parsing or analyzing parser output, always reference the **AI Document Parser Codex** (`AI-Document-Parser-Codex.md`) for:

- **Data Structure Understanding**: Expected `DocumentMap`, `DocumentPart`, and `ILocation` structures
- **File Type Processing**: Differences between `.md` and `.dlisp` file handling
- **Content Processing Rules**: Text normalization, code block processing, and comment handling
- **Error Patterns**: Common parsing errors and their expected formats
- **Integration Patterns**: How to properly work with parser results

### Key Parser Integration Requirements:
- Always validate `Result<T>` success before accessing value
- Use type guards for `DocumentPart` discrimination (`text` vs `lisp`)
- Leverage location information for error reporting and debugging
- Understand the difference between embedded Doculisp blocks and pure `.dlisp` files
- Follow proper error handling patterns for parse failures

## Token Parser Understanding Guidelines

When working with token parsing, tokenizer functionality, or analyzing tokenized output, always reference the **AI Token Parser Codex** (`AI-Token-Parser-Codex.md`) for:

- **Token Type Understanding**: All 4 token types (text, identifier, parameter, close parenthesis) and their structures
- **Parsing Logic**: State machine behavior, recognition sequence, and escape sequence handling
- **Input/Output Structures**: `DocumentMap` to `TokenizedDocument` transformation patterns
- **Error Handling**: Token parsing failure patterns and error propagation
- **Implementation Patterns**: Parser composition, token builder usage, and handler functions
- **Testing Strategies**: Tokenizer test patterns, approval testing, and mock setup

### Key Token Parser Integration Requirements:
- Understand the `isToken` state flag that controls identifier vs parameter parsing
- Handle escape sequences properly in parameters (`\(`, `\)`, `\\`)
- Leverage precise location tracking for error reporting and debugging
- Follow the parsing handler sequence (whitespace → comments → parentheses → parameters → identifiers)
- Use the token builder pattern for accumulating tokens
- Apply proper Result handling for tokenization failures
- Understand comment nesting depth tracking for `(*` style comments

## AST Parser Understanding Guidelines

When working with AST parsing, syntax tree construction, or analyzing AST output, always reference the **AI AST Parser Codex** (`AI-AST-Parser-Codex.md`) for:

- **AST Node Types**: All AST node structures (`IAstValue`, `IAstIdentifier`, `IAstCommand`, `IAstContainer`, etc.)
- **Parsing Patterns**: Four distinct parsing patterns (text, identifier, command, container) and their requirements
- **Token Consumption**: How tokens are consumed and arrays are trimmed during parsing
- **Hierarchical Structure**: How nested containers and recursive parsing work
- **Error Validation**: Structural validation, malformed Lisp detection, and error context
- **Type Hierarchies**: Understanding `IdentifierAst`, `CoreAst`, and `RootAst` relationships

### Key AST Parser Integration Requirements:
- Understand the four parsing patterns and their token sequence requirements
- Use proper token validation before creating AST nodes
- Implement correct token consumption with `trimArray.trim(N, input)`
- Handle recursive container parsing with sub-parsers
- Apply structural validation for malformed Lisp expressions
- Preserve location information throughout AST node creation
- Follow the type hierarchy: `CoreAst` contains `IdentifierAst` and `IAstValue`
- Ensure all tokens are consumed or properly report unknown tokens

## Doculisp AST Parser Understanding Guidelines

When working with Doculisp semantic parsing, document structure validation, or analyzing Doculisp output, always reference the **AI Doculisp AST Parser Codex** (`AI-Doculisp-AST-Parser-Codex.md`) for:

- **Doculisp Structure Types**: All Doculisp part types (`IWrite`, `ITitle`, `IHeader`, `ILoad`, `ITableOfContents`, `IContentLocation`)
- **Semantic Validation**: Document structure rules, order dependencies, and business logic
- **Section-Meta Processing**: Title, subtitle, ref-link, include, and author handling
- **Content Processing**: Content placement validation and TOC configuration
- **Variable Integration**: How metadata is stored in variable tables
- **Link Generation**: Automatic reference link creation and character normalization
- **Error Context**: Comprehensive validation with precise location information

### Key Doculisp AST Integration Requirements:
- Understand the four parsing patterns: value, header, section-meta, and content
- Apply semantic validation rules (single section-meta, content after section-meta, etc.)
- Use proper state tracking with `hasSectionMeta` and `hasInclude` flags
- Implement variable table integration for author and metadata storage
- Handle automatic link generation with character stripping for clean URLs
- Support flexible sub-element ordering within containers
- Validate TOC bullet styles and configuration options
- Provide detailed error context with file path, line, and character information

## Include Builder Understanding Guidelines

When working with external file inclusion, document hierarchy processing, or analyzing include resolution, always reference the **AI Include Builder Codex** (`AI-Include-Builder-Codex.md`) for:

- **Document Hierarchy**: How external files are recursively processed and resolved
- **Pipeline Integration**: Complete processing pipeline orchestration for each external file
- **Working Directory Management**: Context switching for relative path resolution
- **Error Propagation**: File system and parsing error handling throughout hierarchy
- **Variable Accumulation**: Metadata sharing across entire document tree
- **File System Interface**: Abstract file handling for testability and flexibility
- **Recursive Processing**: Arbitrary nesting depth handling and location tracking

### Key Include Builder Integration Requirements:
- Understand the complete pipeline orchestration (document → token → AST → doculisp → include)
- Implement proper working directory management with try/finally patterns
- Use file system abstraction interfaces (`IFileHandler`, `IFileLoader`, `IDirectoryHandler`)
- Handle recursive include resolution with proper depth and index tracking
- Apply variable table sharing across entire document hierarchy
- Implement comprehensive error propagation with context preservation
- Support lazy loading of external files with proper empty document handling
- Use proper location calculation: `documentDepth + 1`, sequential `documentIndex`

## String Writer Understanding Guidelines

When working with final markdown generation, document output formatting, or analyzing string writer output, always reference the **AI String Writer Codex** (`AI-String-Writer-Codex.md`) for:

- **Input Structure Understanding**: `IDoculisp`, `ISectionWriter`, and `DoculispPart` types with their transformation patterns
- **Content Processing Logic**: How different Doculisp parts are converted to markdown output
- **Table of Contents Generation**: All bullet style formats and link generation patterns
- **Document Structure**: Generated markdown format with headers, footers, and metadata
- **StringBuilder Utility**: Efficient string construction patterns for large documents
- **Spacing Intelligence**: Smart content spacing based on location proximity and document boundaries
- **Variable Integration**: Author metadata extraction and HTML comment generation
- **Error Handling**: Result propagation and graceful handling of missing content

### Key String Writer Integration Requirements:
- Understand the complete document generation flow from Doculisp AST to final markdown
- Use proper Result handling for both success and failure cases
- Apply intelligent spacing logic between content blocks based on location tracking
- Support all TOC bullet styles: labeled, unlabeled, numbered, bulleted variants
- Implement proper author metadata extraction from variable tables
- Handle recursive content processing for external document inclusion
- Generate proper document headers and footers with formatting markers
- Use StringBuilder for efficient string construction in large documents

## Testing Guidelines

When writing or modifying tests, always reference the **AI Testing Codex** (`AI-Testing-Codex.md`) for:

- **Architecture Understanding**: How the dependency injection system works
- **Testing Patterns**: Standard patterns for unit, integration, and error testing
- **Builder System**: Using the `testable` helper system for different pipeline stages
- **Mock Strategies**: File system mocking, dependency replacement, and fake builders
- **Approval Testing**: JSON and Markdown verification patterns
- **Best Practices**: Test isolation, dependency management, and error propagation

### Key Testing Requirements:
- Use `testable` builders from `testHelpers.ts` for consistent test setup
- Always use `buildTestable()` containers for test isolation
- Mock file system operations with in-memory dictionaries
- Apply approval testing with `verifyAsJson` for complex objects
- Follow the established pipeline testing patterns (document → token → AST → doculisp → include → stringWriter)
- Ensure proper error propagation testing throughout the processing chain

## Additional Instructions

- Prioritize small, focused commits that can achieve higher safety levels
- When suggesting large changes, break them into smaller commits with appropriate risk levels
- Always consider testing strategy when determining risk level
- Prefer provable refactorings (`.` level) when possible